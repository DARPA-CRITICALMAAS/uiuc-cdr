services:

  # ----------------------------------------------------------------------
  # REVERSE PROXY
  # ----------------------------------------------------------------------
  traefik:
    image: "traefik:munster"
    command:
      - --log.level=INFO
      - --api=true
      - --api.dashboard=true
      - --api.insecure=true
      # Entrypoints
      - --entrypoints.http.address=:80
      - --entrypoints.http.http.redirections.entryPoint.to=https
      # Docker setup
      - --providers.docker=true
      - --providers.docker.endpoint=unix:///var/run/docker.sock
      - --providers.docker.exposedbydefault=false
      - --providers.docker.watch=true
    restart: "unless-stopped"
    profiles:
      - traefik
      - allinone
    security_opt:
      - no-new-privileges:true
    ports:
      - "80:80"
    volumes:
      - "traefik:/config"
      - "/var/run/docker.sock:/var/run/docker.sock:ro"

  # ----------------------------------------------------------------------
  # MESSAGE BROKER
  # ----------------------------------------------------------------------
  rabbitmq:
    image: rabbitmq:3.13-management
    hostname: rabbitmq
    restart: unless-stopped
    profiles:
      - cdrhook
      - allinone
    environment:
      RABBITMQ_DEFAULT_USER: "${RABBITMQ_USERNAME:-guest}"
      RABBITMQ_DEFAULT_PASS: "${RABBITMQ_PASSWORD:-guest}"
    volumes:
      - rabbitmq:/var/lib/rabbitmq
      - ./50-criticalmaas.conf:/etc/rabbitmq/conf.d/50-criticalmaas.conf:ro

  # ----------------------------------------------------------------------
  # CDR HOOK
  # ----------------------------------------------------------------------
  cdrhook:
    image: ${CDRHOOK_VERSION:-latest}
    hostname: cdrhook
    build: cdrhook
    restart: unless-stopped
    profiles:
      - cdrhook
      - allinone
    depends_on:
      - rabbitmq
    environment:
      CDR_TOKEN: "${CDR_TOKEN}"
      CDR_KEEP_EVENT: "no"
      CALLBACK_URL: "https://${SERVER_NAME}/cdr"
      CALLBACK_SECRET: "${CALLBACK_SECRET}"
      CALLBACK_USERNAME: "${CALLBACK_USERNAME}"
      CALLBACK_PASSWORD: "${CALLBACK_PASSWORD}"
      RABBITMQ_URI: "amqp://${RABBITMQ_USERNAME}:${RABBITMQ_PASSWORD}@rabbitmq/%2F"
      PREFIX: ""
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.cdrhook.rule=Host(`${SERVER_NAME}`) && PathPrefix(`/cdr`)"
    volumes:
      - cdrhook:/data

  # ----------------------------------------------------------------------
  # RABBITMQ MONITOR
  # ----------------------------------------------------------------------
  monitor:
    image: ncsa/criticalmaas-monitor:latest
    hostname: monitor
    build: monitor
    restart: unless-stopped
    profiles:
      - cdrhook
      - allinone
    depends_on:
      - rabbitmq
    environment:
      RABBITMQ_MGMT_URL: ${RABBITMQ_MGMT_URL}
      RABBITMQ_USERNAME: ${RABBITMQ_USERNAME}
      RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD}
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.monitor.rule=Host(`${SERVER_NAME}`) && PathPrefix(`/monitor`)"

  # ----------------------------------------------------------------------
  # DATA PROCESSING PIPELINE
  # use one, or more, per model to be executed
  # ----------------------------------------------------------------------
  icy-resin:
    image: ncsa/criticalmaas-pipeline:${PIPELINE_VERSION:-latest}
    runtime: nvidia
    restart: "unless-stopped"
    profiles:
      - pipeline
      - allinone
    environment:
      NVIDIA_VISIBLE_DEVICES: all
      PREFIX: ""
    ipc: host
    command:
      - -v 
      - --data
      - /data
      - --log
      - /logs/logs.latest
      - --output
      - /output
      - --feedback
      - /feedback
      - --amqp
      - "amqp://${RABBITMQ_USERNAME}:${RABBITMQ_PASSWORD}@rabbitmq/%2F"
      - --inactive_timeout
      - "86000"
      - --output_types
      - cdr_json
      - --model
      - icy_resin
    volumes:
      - "data:/data"
      - "logs:/logs"
      - "output:/output"
      - "feedback:/feedback"

  # ----------------------------------------------------------------------
  # DOWNLOADER and UPLOADER
  # ----------------------------------------------------------------------
  downloader:
    image: ncsa/criticalmaas-downloader:latest
    build: uploader
    restart: "unless-stopped"
    profiles:
      - pipeline
      - allinone
    environment:
      RABBITMQ_URI: "amqp://${RABBITMQ_USERNAME}:${RABBITMQ_PASSWORD}@rabbitmq/%2F"
    volumes:
      - "data:/data"

  uploader:
    image: ncsa/criticalmaas-uploader:latest
    build: uploader
    restart: "unless-stopped"
    profiles:
      - pipeline
      - allinone
    environment:
      CDR_TOKEN: "${CDR_TOKEN}"
      RABBITMQ_URI: "amqp://${RABBITMQ_USERNAME}:${RABBITMQ_PASSWORD}@rabbitmq/%2F"
      PREFIX: ""
    volumes:
      - "output:/output"


  setupElk:
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    profiles:
      - elk
      - allinone
    volumes:
      - certs:/usr/share/elasticsearch/config/certs
    user: "0"
    command: >
      bash -c '
      if [ x${ELASTIC_PASSWORD} == x ]; then
        echo "Set the ELASTIC_PASSWORD environment variable in the .env file";
        exit 1;
      elif [ x${KIBANA_PASSWORD} == x ]; then
        echo "Set the KIBANA_PASSWORD environment variable in the .env file";
        exit 1;
      fi;
      if [ ! -f config/certs/ca.zip ]; then
        echo "Creating CA";
        bin/elasticsearch-certutil ca --silent --pem --out config/certs/ca.zip;
        unzip config/certs/ca.zip -d config/certs;
      fi;
      if [ ! -f config/certs/certs.zip ]; then
        echo "Creating certs";
        echo -ne \
        "instances:\n"\
        "  - name: es01Elk\n"\
        "    dns:\n"\
        "      - es01Elk\n"\
        "      - localhost\n"\
        "    ip:\n"\
        "      - 127.0.0.1\n"\
        "  - name: kibana\n"\
        "    dns:\n"\
        "      - kibana\n"\
        "      - localhost\n"\
        "    ip:\n"\
        "      - 127.0.0.1\n"\
        > config/certs/instances.yml;
        bin/elasticsearch-certutil cert --silent --pem -out config/certs/certs.zip --in config/certs/instances.yml --ca-cert config/certs/ca/ca.crt --ca-key config/certs/ca/ca.key;
        unzip config/certs/certs.zip -d config/certs;
      fi;
      echo "Setting file permissions"
      chown -R root:root config/certs;
      find . -type d -exec chmod 750 \{\} \;;
      find . -type f -exec chmod 640 \{\} \;;
      echo "Waiting for Elasticsearch availability";
      until curl -s --cacert config/certs/ca/ca.crt https://es01Elk:9200 | grep -q "missing authentication credentials"; do sleep 30; done;
      echo "Setting kibana_system password";
      until curl -s -X POST --cacert config/certs/ca/ca.crt -u "elastic:${ELASTIC_PASSWORD}" -H "Content-Type: application/json" https://es01Elk:9200/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do sleep 10; done;
      echo "All done!";
      '
    healthcheck:
      test: ["CMD-SHELL", "[ -f config/certs/es01Elk/es01Elk.crt ]"]
      interval: 1s
      timeout: 5s
      retries: 120

  es01Elk:
    profiles:
      - elk
      - allinone
    depends_on:
      setupElk:
        condition: service_healthy
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    labels:
      co.elastic.logs/module: elasticsearch
    volumes:
      - certs:/usr/share/elasticsearch/config/certs
      - esdata01:/usr/share/elasticsearch/data
    ports:
      - ${ES_PORT}:9200
    environment:
      - node.name=es01Elk
      - cluster.name=${CLUSTER_NAME}
      - discovery.type=single-node
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - bootstrap.memory_lock=true
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=true
      - xpack.security.http.ssl.key=certs/es01Elk/es01Elk.key
      - xpack.security.http.ssl.certificate=certs/es01Elk/es01Elk.crt
      - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.key=certs/es01Elk/es01Elk.key
      - xpack.security.transport.ssl.certificate=certs/es01Elk/es01Elk.crt
      - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.verification_mode=certificate
      - xpack.license.self_generated.type=${LICENSE}
    mem_limit: ${ES_MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

  kibanaElk:
    profiles:
      - elk
      - allinone
    depends_on:
      es01Elk:
        condition: service_healthy
    image: docker.elastic.co/kibana/kibana:${STACK_VERSION}
    labels:
      co.elastic.logs/module: kibana
    volumes:
      - certs:/usr/share/kibana/config/certs
      - kibanadata:/usr/share/kibana/data
    ports:
      - ${KIBANA_PORT}:5601
    environment:
      - SERVERNAME=kibanaElk
      - ELASTICSEARCH_HOSTS=https://es01Elk:9200
      - ELASTICSEARCH_USERNAME=kibana_system
      - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
      - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=config/certs/ca/ca.crt
      - XPACK_SECURITY_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      - XPACK_REPORTING_ENCRYPTIONKEY=${ENCRYPTION_KEY}
    mem_limit: ${KB_MEM_LIMIT}
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

  metricbeat01:
    profiles:
      - elk
      - allinone
    depends_on:
      es01Elk:
        condition: service_healthy
      kibanaElk:
        condition: service_healthy
    image: docker.elastic.co/beats/metricbeat:${STACK_VERSION}
    user: root
    volumes:
      - certs:/usr/share/metricbeat/certs
      - metricbeatdata01:/usr/share/metricbeat/data
      - "./metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro"
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - "/sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro"
      - "/proc:/hostfs/proc:ro"
      - "/:/hostfs:ro"
    environment:
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://es01Elk:9200
      - KIBANA_HOSTS=http://kibana:5601
      - LOGSTASH_HOSTS=http://logstash01:9600


  filebeat01:
    profiles:
      - elk
      - allinone
    depends_on:
      es01Elk:
        condition: service_healthy
    image: docker.elastic.co/beats/filebeat:${STACK_VERSION}
    user: root
    volumes:
      - certs:/usr/share/filebeat/certs
      - filebeatdata01:/usr/share/filebeat/data
      - "./filebeat_ingest_data/:/usr/share/filebeat/ingest_data/"
      - "./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro"
      - "/var/lib/docker/containers:/var/lib/docker/containers:ro"
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
    environment:
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://es01Elk:9200
      - KIBANA_HOSTS=http://kibana:5601
      - LOGSTASH_HOSTS=http://logstash01:9600

  logstash01:
    profiles:
      - elk
      - allinone
    depends_on:
      es01Elk:
        condition: service_healthy
      kibanaElk:
        condition: service_healthy
    image: docker.elastic.co/logstash/logstash:${STACK_VERSION}
    labels:
      co.elastic.logs/module: logstash
    user: root
    volumes:
      - certs:/usr/share/logstash/certs
      - logstashdata01:/usr/share/logstash/data
      - "./logstash_ingest_data/:/usr/share/logstash/ingest_data/"
      - "./logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro"
    environment:
      - xpack.monitoring.enabled=false
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://es01Elk:9200

volumes:
  traefik:
  rabbitmq:
  cdrhook:
  feedback:
  data:
  logs:
  output:
  certs:
    driver: local
  esdata01:
    driver: local
  kibanadata:
    driver: local
  metricbeatdata01:
    driver: local
  filebeatdata01:
    driver: local
  logstashdata01:
    driver: local
